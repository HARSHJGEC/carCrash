{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout,AveragePooling2D,Softmax\n",
        "from tensorflow.keras.layers import Conv3D,LayerNormalization,ReLU\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "xRc4L8R9z21v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j2POQE0Ou4IX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d asefjamilajwad/car-crash-dataset-ccd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJqZZuCtwx0-",
        "outputId": "d1531334-031b-49ac-9e1a-429585343822"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/asefjamilajwad/car-crash-dataset-ccd\n",
            "License(s): other\n",
            "Downloading car-crash-dataset-ccd.zip to /content\n",
            "100% 7.60G/7.61G [02:06<00:00, 67.4MB/s]\n",
            "100% 7.61G/7.61G [02:06<00:00, 64.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/car-crash-dataset-ccd.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "JC6cLztaxkgT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "Z6i-fxIe4i8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv(\"/content/Severity.csv\")\n",
        "# num_videos=df1.shape[0]\n",
        "num_videos=5"
      ],
      "metadata": {
        "id": "XquScx6LyhzJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "# Define source and destination paths\n",
        "source_path = \"/content/CrashBest/\"\n",
        "dest_path = \"/content/test1/\"\n",
        "os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "# List all files in the source directory\n",
        "all_files = os.listdir(source_path)\n",
        "\n",
        "# Copy the first 100 files\n",
        "for video_name in range(1,num_videos+1):\n",
        "  for i in range(1,51):\n",
        "    frame_number = str(i).zfill(2)  # Ensure two digits with leading zeros\n",
        "    file_name = f\"C_{video_name:06}_{frame_number}.jpg\"\n",
        "\n",
        "    shutil.copy(source_path + file_name, dest_path + file_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEJUv-7X9HCE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH =dest_path\n",
        "TABLENAME = \"/content/Crash_Table.csv\""
      ],
      "metadata": {
        "id": "1HhVFkkX0C0e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(TABLENAME)\n",
        "col_class=\"Severity of the Crash\"\n",
        "df[col_class] = df1[col_class]\n",
        "df[col_class] = df[col_class].fillna('minor')#fill NAN with minor of col_class\n",
        "df[col_class] = df[col_class].str.lower()#convert into lower case\n",
        "num_classes = df[col_class].unique()\n",
        "label_encoding = {category: [1 if category == unique else 0 for unique in num_classes] for category in num_classes}\n",
        "img_size=[225,225]"
      ],
      "metadata": {
        "id": "XDTjFFqpzEW8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(video_name):\n",
        "  frames = []\n",
        "  for i in range(1, 51):\n",
        "    frame_number = str(i).zfill(2)  # Ensure two digits with leading zeros\n",
        "    file_name = f\"C_{video_name:06}_{frame_number}.jpg\"  # Six-digit video name\n",
        "    frame_path = os.path.join(BASE_PATH, file_name)\n",
        "    if os.path.exists(frame_path):\n",
        "      img = cv2.imread(frame_path)  # Use OpenCV to read image\n",
        "      img = cv2.resize(img, (img_size[0], img_size[1]))  # Resize image\n",
        "      frames.append(img)\n",
        "  return tf.convert_to_tensor(frames, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "aKbEnJBobf-l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_func(data):\n",
        "  accident_frame_atten=0.8\n",
        "  non_accident_frame_atten=0.2\n",
        "  frame_scene=[]\n",
        "  for index in range(1,51):\n",
        "    frame_num=f\"frame_{index}\"\n",
        "    if df[frame_num][data]==1:\n",
        "      frame_scene.append(accident_frame_atten)\n",
        "    else:\n",
        "      frame_scene.append(non_accident_frame_atten)\n",
        "  return tf.convert_to_tensor(frame_scene, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "0yWXVEtEFvM_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def Create_dataset():\n",
        "  images_list=[]\n",
        "  labels_list=[]\n",
        "  attention_list=[]\n",
        "  for data in range(0,num_videos):\n",
        "    frame=load_video(df['vidname'][data])\n",
        "    images_list.append(frame)\n",
        "    labels_list.append(label_encoding[df[col_class][data]])\n",
        "    attention_list.append(attention_func(data))\n",
        "  image_array=np.array(images_list)\n",
        "  labels_array=np.array(labels_list)\n",
        "  attention_array=np.array(attention_list)\n",
        "  train_images, temp_images, train_labels, temp_labels, train_attentions, temp_attentions = train_test_split(\n",
        "      image_array, labels_array, attention_array, train_size=0.7, random_state=42, shuffle=True\n",
        "  )\n",
        "\n",
        "  val_images, test_images, val_labels, test_labels, val_attentions, test_attentions = train_test_split(\n",
        "      temp_images, temp_labels, temp_attentions, test_size=0.5, random_state=42, shuffle=True\n",
        "  )\n",
        "  train_images=tf.convert_to_tensor(train_images)\n",
        "  val_images=tf.convert_to_tensor(val_images)\n",
        "  test_images=tf.convert_to_tensor(test_images)\n",
        "  train_attentions=tf.convert_to_tensor(train_attentions)\n",
        "  val_attentions=tf.convert_to_tensor(val_attentions)\n",
        "  test_attentions=tf.convert_to_tensor(test_attentions)\n",
        "  train_labels=tf.convert_to_tensor(train_labels)\n",
        "  val_labels=tf.convert_to_tensor(val_labels)\n",
        "  test_labels=tf.convert_to_tensor(test_labels)\n",
        "  return train_images, val_images, test_images,  train_labels,val_labels, test_labels,  train_attentions, val_attentions, test_attentions\n",
        "train_images, val_images, test_images,  train_labels,val_labels, test_labels,  train_attentions, val_attentions, test_attentions=Create_dataset()\n"
      ],
      "metadata": {
        "id": "qlmY9FxN1D0g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "qkXVJvQ64zC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2Plus1D(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, padding):\n",
        "        super().__init__()\n",
        "        self.seq = Sequential([\n",
        "            # Spatial decomposition\n",
        "            Conv3D(filters=filters,\n",
        "                  kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
        "                  padding=padding),\n",
        "            # Temporal decomposition\n",
        "            Conv3D(filters=filters,\n",
        "                  kernel_size=(kernel_size[0], 1, 1),\n",
        "                  padding=padding)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.seq(inputs)\n"
      ],
      "metadata": {
        "id": "Ig7RyFqC419e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CombineTemporalLayers(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CombineTemporalLayers, self).__init__()\n",
        "        self.conv3d = tf.keras.layers.Conv3D(\n",
        "            filters=3,\n",
        "            kernel_size=(50, 1, 1),\n",
        "            strides=(1, 1, 1),\n",
        "            padding='valid',\n",
        "            activation=None,\n",
        "            use_bias=False\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply Conv3D to combine the layers\n",
        "        x = self.conv3d(inputs)\n",
        "        # Squeeze the combined layer dimension\n",
        "        x = tf.squeeze(x, axis=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_-HCxTMJ_0-R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, attention):\n",
        "        # Expand dimensions of the attention tensor to match the dimensions of x\n",
        "        attention = tf.expand_dims(tf.expand_dims(tf.expand_dims(attention, axis=-1), axis=-1), axis=-1)\n",
        "        # Perform element-wise multiplication\n",
        "        return x * attention"
      ],
      "metadata": {
        "id": "tP08J-nB_-06"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.seq = keras.Sequential([\n",
        "        Conv2Plus1D(filters=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same'),\n",
        "        LayerNormalization(),\n",
        "        ReLU()\n",
        "    ])\n",
        "    self.attention=AttentionLayer()\n",
        "    self.combine=CombineTemporalLayers()\n",
        "  def call(self, x,attention):\n",
        "     x=self.attention(self.seq(x),attention)\n",
        "     return self.combine(x)\n"
      ],
      "metadata": {
        "id": "tQjXekdhAEQ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class inception(keras.Model):\n",
        "    def __init__(self,num_first_filter,num_second_filter):\n",
        "        super().__init__()\n",
        "        self.conv1=Sequential([Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2A=Sequential([Conv2D(num_second_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2B=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2C=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.pool=MaxPooling2D(pool_size=2, strides=1, padding='same')\n",
        "    def call(self,inputs):\n",
        "        x=self.conv2B(self.conv1(inputs))\n",
        "        # print(x.shape)\n",
        "        x1=self.conv2C(x)\n",
        "        # print(x1.shape)\n",
        "        x2=self.conv2A(self.pool(inputs))\n",
        "        x3=self.conv2A(inputs)\n",
        "\n",
        "        output=tf.concat([x,x1,x2,x3],-1)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "1y7No8xhAKL7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class inception_reduction(keras.Model):\n",
        "    def __init__(self,num_first_filter,num_second_filter,num_third_filter):\n",
        "        super(inception_reduction,self).__init__()\n",
        "        self.conv1=Sequential([Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv1A=Sequential([Conv2D(num_first_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2A=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=2,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2B=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=2,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "\n",
        "        self.pool=MaxPooling2D(pool_size=2, strides=2)\n",
        "        self.conv3=Sequential([Conv2D(num_third_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "\n",
        "    def call(self,inputs):\n",
        "        # x=self.conv64(inputs)\n",
        "        x=self.conv1A(self.conv1(inputs))\n",
        "        # print(x.shape)\n",
        "        x=self.conv2A(x)\n",
        "        # print(x.shape)\n",
        "        x1=self.conv2B(self.conv1(inputs))\n",
        "        x2=self.conv3(self.pool(inputs))\n",
        "        output=tf.concat([x,x1,x2],-1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "DDH_SDoiAPiI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class inception_resnet(keras.Model):\n",
        "    def __init__(self,num_first_filter,num_second_filter):\n",
        "        super(inception_resnet,self).__init__()\n",
        "        self.conv1=Sequential([Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2=Sequential([Conv2D(num_second_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv1A=Sequential([Conv2D(num_first_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2A=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2B=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "\n",
        "    def call(self,inputs):\n",
        "        x=self.conv1A(self.conv1(inputs))\n",
        "        # print(x.shape)\n",
        "        x=self.conv2A(x)\n",
        "        # print(x.shape)\n",
        "        x1=self.conv2B(self.conv1(inputs))\n",
        "        # print(x1.shape)\n",
        "        x2=self.conv2(inputs)\n",
        "        # print(x2.shape)\n",
        "        output=tf.concat([x,x1,x2],-1)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "14uLzzB8AXYp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class inception_resnet_V2(keras.Model):\n",
        "    def __init__(self,num_first_filter,num_second_filter,num_third_filter):\n",
        "        super(inception_resnet_V2,self).__init__()\n",
        "        self.conv1=Sequential([Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv3=Sequential([Conv2D(num_third_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2=Sequential([Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv3A=Sequential([Conv2D(num_third_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv3B=Sequential([Conv2D(num_third_filter,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "\n",
        "        self.pool=MaxPooling2D(pool_size=2, strides=1,padding='same')\n",
        "        self.conv3C=Sequential([Conv2D(num_third_filter,kernel_size=(1,1),strides=1,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "\n",
        "    def call(self,inputs):\n",
        "        x=self.conv2(self.conv1(inputs))\n",
        "        # print(x.shape)\n",
        "        x=self.conv3A(x)\n",
        "        # print(x.shape)\n",
        "        x1=self.conv3B(self.conv1(inputs))\n",
        "        # print(x1.shape)\n",
        "        x2=self.conv3(inputs)\n",
        "        # print(x2.shape)\n",
        "        x3=self.conv3C(self.pool(inputs))\n",
        "        output=tf.concat([x,x1,x2,x3],-1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "Uj2mSyGmAdLt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Attention,self).__init__()\n",
        "        self.conv1=Conv2D(1024,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
        "        self.bn1=BatchNormalization()\n",
        "        self.softmax=Softmax(axis=-1)\n",
        "    def call(self,input1,input2):\n",
        "        f=self.bn1(self.conv1(input1))\n",
        "        G=tf.multiply(f,input2)\n",
        "        p=self.softmax(G)\n",
        "        temp=tf.multiply(p,f)\n",
        "        attn=tf.reduce_sum(temp,axis=[1,2])\n",
        "        return attn\n"
      ],
      "metadata": {
        "id": "mdROjNbUAizg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neural_Network(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1=Sequential([Conv2D(32,kernel_size=(3,3),strides=2,padding='valid'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.conv2=Sequential([Conv2D(64,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.pool3=MaxPooling2D(pool_size=2, strides=2, padding='valid')\n",
        "        self.inception4=inception(48,64)\n",
        "        self.inception5=inception(48,64)\n",
        "        self.inception_red6=inception_reduction(64,96,192)\n",
        "        self.inception_red10=inception_reduction(96,112,384)\n",
        "        self.inception_resnet7=inception_resnet(96,128)\n",
        "        self.inception_resnet8=inception_resnet(96,128)\n",
        "        self.inception_resnet11=inception_resnet_V2(112,128,152)\n",
        "        self.inception_resnet12=inception_resnet_V2(112,128,152)\n",
        "        self.inception_red14=inception_reduction(112,128,608)\n",
        "        self.conv15=Sequential([Conv2D(1024,kernel_size=(3,3),strides=1,padding='same'),\n",
        "                                BatchNormalization(),\n",
        "                                ReLU()])\n",
        "        self.pool16=AveragePooling2D(pool_size=(7,7))\n",
        "        self.attention1=Attention()\n",
        "        self.attention2=Attention()\n",
        "        self.ffn18=Dense(512, activation='relu')\n",
        "        self.bn18=BatchNormalization()\n",
        "        # self.ffn19=Dense(2, activation='relu')\n",
        "        # self.softmax19=Softmax()\n",
        "    def call(self,inputs):\n",
        "        x_1=self.conv1(inputs)\n",
        "        print(x_1.shape)\n",
        "        x_2=self.conv2(x_1)\n",
        "        print(x_2.shape)\n",
        "        x_3=self.pool3(x_2)\n",
        "        print(x_3.shape)\n",
        "        x_4=self.inception4(x_3)\n",
        "        x_5=self.inception5(x_4)\n",
        "        x_6=self.inception_red6(x_5)\n",
        "        print(x_6.shape)\n",
        "        x_7=self.inception_resnet7(x_6)\n",
        "        print(x_7.shape)\n",
        "        x_8=self.inception_resnet8(x_7)\n",
        "        x_10=self.inception_red10(x_8)\n",
        "        x_11=self.inception_resnet11(x_10)\n",
        "        x_12=self.inception_resnet12(x_11)\n",
        "        x_14=self.inception_red14(x_12)\n",
        "        x_15=self.conv15(x_14)\n",
        "        x_16=self.pool16(x_15)\n",
        "        x_9=self.attention1(x_8,x_16)\n",
        "        x_13=self.attention2(x_12,x_16)\n",
        "        x_17=tf.concat([x_9,x_13],-1)\n",
        "        x_18=self.bn18(self.ffn18(x_17))\n",
        "        # x_19=self.ffn19(x_18)\n",
        "        # logits_softmax, logits_centers = tf.split(x_19, [2, 2], axis=-1)\n",
        "        # print(logits_centers.shape)\n",
        "        # output=self.softmax19(x_19)\n",
        "        output=x_18\n",
        "        print(f'output{output.shape}')\n",
        "        return output"
      ],
      "metadata": {
        "id": "lEVxOMFqA2Tb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decision_Network(keras.Model):\n",
        "    def __init__(self, num_classes, output_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = Dense(2, activation='relu')\n",
        "        self.conv2 = Dense(2, activation='relu')\n",
        "        self.softmax = Softmax()\n",
        "        self.Encoder = Encoder(filters=3, kernel_size=(3, 3, 3))\n",
        "        self.NN1 = Neural_Network()\n",
        "        self.centers = tf.Variable(tf.random.normal((num_classes, output_dim)), trainable=True)\n",
        "        self.g = 0.5  # learning rate for the class centers\n",
        "\n",
        "    def call(self, inputs, attention):\n",
        "        x = self.Encoder(inputs, attention)\n",
        "        x = self.conv1(self.NN1(x))\n",
        "        softmax_output = self.softmax(x)\n",
        "        center = self.conv2(self.NN1(inputs))\n",
        "        output = softmax_output + center\n",
        "        return output\n",
        "\n",
        "    def center_loss(self, features, labels):\n",
        "        batch_size = tf.shape(features)[0]\n",
        "        expanded_features = tf.expand_dims(features, 1)\n",
        "        expanded_centers = tf.expand_dims(self.centers, 0)\n",
        "        squared_distances = tf.reduce_sum(tf.square(expanded_features - expanded_centers), axis=2)\n",
        "\n",
        "        labels = tf.expand_dims(labels, axis=1)\n",
        "        mask = tf.cast(tf.equal(labels, tf.range(self.centers.shape[0])), dtype=tf.float32)\n",
        "        masked_distances = squared_distances * mask\n",
        "\n",
        "        epsilon = 1e-6\n",
        "        average_loss = tf.reduce_sum(masked_distances) / (batch_size * self.centers.shape[0] + epsilon)\n",
        "        return average_loss\n",
        "\n",
        "    def update_centers(self, features, labels):\n",
        "        delta_centers = tf.zeros_like(self.centers)\n",
        "        for i in range(tf.shape(features)[0]):\n",
        "            feature = features[i]\n",
        "            label = labels[i]\n",
        "            delta_centers += tf.where(tf.equal(tf.range(self.centers.shape[0]), label), feature - self.centers[label], 0)\n",
        "\n",
        "        label_counts = tf.reduce_sum(tf.cast(tf.equal(tf.expand_dims(labels, axis=1), tf.range(self.centers.shape[0])), tf.float32), axis=0)\n",
        "        delta_centers = delta_centers / (label_counts[:, None] + 1e-6)\n",
        "\n",
        "        self.centers.assign_sub(self.g * delta_centers)\n",
        "\n",
        "    def combined_loss(self, y_true, y_pred, features):\n",
        "        softmax_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "        center_loss_value = self.center_loss(features, tf.argmax(y_true, axis=1))\n",
        "        d = 0.006\n",
        "        total_loss = softmax_loss + d * center_loss_value\n",
        "        return total_loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        inputs, y_true = data\n",
        "        attention = None  # Assuming no attention input for simplicity\n",
        "        with tf.GradientTape() as tape:\n",
        "            features = self.NN1(self.Encoder(inputs, attention))\n",
        "            y_pred = self(inputs, attention)\n",
        "            loss = self.combined_loss(y_true, y_pred, features)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.update_centers(features, tf.argmax(y_true, axis=1))\n",
        "\n",
        "        self.compiled_metrics.update_state(y_true, y_pred)\n",
        "\n",
        "        return {\"loss\": loss, **{m.name: m.result() for m in self.metrics}}\n",
        "\n",
        "    def compile(self, optimizer, loss_weights=None, metrics=None):\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "# Example usage\n",
        "model = Decision_Network(num_classes=4, output_dim=4)\n",
        "model.compile(optimizer=SGD(), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yf5bqKxqA42i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([train_images,train_attentions], train_labels, epochs=5, validation_data=([val_images,val_attentions], val_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate([test_images,test_attentions], test_labels)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "4632Da0dEhtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}